import json
import os
import sys
from typing import Dict, Any, Optional, List
from pathlib import Path
import re

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from api.llm import LLMClient


class JobAnalyzer:
    """
    å²—ä½åˆ†æå™¨
    ç”¨äºåˆ†æèŒä½æè¿°ã€å…¬å¸åç§°å’Œå²—ä½æ ‡é¢˜ï¼Œæä¾›ä¸šåŠ¡æ¨¡å¼åˆ†æå’Œç›®æ ‡å…¬å¸æ¨è
    """
    
    def __init__(
        self, 
        model: str = "gpt-4-1106-preview", 
        provider: str = "openai",
        temperature: float = 0.3,
        max_tokens: int = 4000,
        top_p: float = 1.0,
        frequency_penalty: float = 0.0,
        presence_penalty: float = 0.0
    ):
        """
        åˆå§‹åŒ–å²—ä½åˆ†æå™¨
        
        Args:
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
            provider: LLMæä¾›å•† ("openai", "gemini", "ali", "groq", "perplexity")
            temperature: æ¸©åº¦å‚æ•° (0-2)ï¼Œé»˜è®¤0.3ç¡®ä¿åˆ›æ„æ€§åˆ†æ
            max_tokens: æœ€å¤§tokenæ•°ï¼Œé»˜è®¤4000æ”¯æŒé•¿ç¯‡åˆ†æ
            top_p: æ ¸é‡‡æ ·å‚æ•° (0-1)ï¼Œé»˜è®¤1.0
            frequency_penalty: é¢‘ç‡æƒ©ç½š (-2.0 to 2.0)ï¼Œé»˜è®¤0.0
            presence_penalty: å­˜åœ¨æƒ©ç½š (-2.0 to 2.0)ï¼Œé»˜è®¤0.0
        """
        self.llm_client = LLMClient()
        self.model = model
        self.provider = provider
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.top_p = top_p
        self.frequency_penalty = frequency_penalty
        self.presence_penalty = presence_penalty
        self.prompt_template = self._load_prompt_template()
    
    def _load_prompt_template(self) -> str:
        """
        ä»æ–‡ä»¶åŠ è½½promptæ¨¡æ¿
        
        Returns:
            promptæ¨¡æ¿å­—ç¬¦ä¸²
        """
        prompt_file = project_root / "prompt" / "job_analysis_prompt.md"
        
        try:
            with open(prompt_file, 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            print(f"Warning: Prompt file not found at {prompt_file}")
            return self._get_default_prompt()
        except Exception as e:
            print(f"Error loading prompt template: {e}")
            return self._get_default_prompt()
    
    def _get_default_prompt(self) -> str:
        """
        è·å–é»˜è®¤çš„promptæ¨¡æ¿
        
        Returns:
            é»˜è®¤promptå­—ç¬¦ä¸²
        """
        return """You are a professional HR analyst and business intelligence expert. 
Analyze the provided job position and company information, then provide comprehensive business model analysis 
and target company recommendations for talent acquisition.

Please provide your analysis in a structured format covering:
1. Business Model Analysis
2. Position Analysis  
3. Target Company Recommendations

Detect the input language and respond in the same language (Chinese or English)."""
    
    def _detect_language(self, text: str) -> str:
        """
        æ£€æµ‹æ–‡æœ¬è¯­è¨€
        
        Args:
            text: è¦æ£€æµ‹çš„æ–‡æœ¬
            
        Returns:
            è¯­è¨€ç±»å‹ ("chinese" æˆ– "english")
        """
        # ç®€å•çš„ä¸­æ–‡å­—ç¬¦æ£€æµ‹
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        total_chars = len(re.sub(r'\s', '', text))
        
        if total_chars == 0:
            return "english"
        
        chinese_ratio = chinese_chars / total_chars
        return "chinese" if chinese_ratio > 0.3 else "english"
    
    def analyze_job(
        self, 
        jd_content: str, 
        company_name: str, 
        position_title: str,
        **kwargs
    ) -> Dict[str, Any]:
        """
        åˆ†æå²—ä½å¹¶è¿”å›åˆ†æç»“æœ
        
        Args:
            jd_content: èŒä½æè¿°å†…å®¹
            company_name: å…¬å¸åç§°
            position_title: å²—ä½æ ‡é¢˜
            **kwargs: ä¼ é€’ç»™LLMçš„é¢å¤–å‚æ•°
            
        Returns:
            åŒ…å«åˆ†æç»“æœçš„å­—å…¸
        """
        # éªŒè¯è¾“å…¥
        if not jd_content or not jd_content.strip():
            return {
                "success": False,
                "error": "Job description content is empty",
                "result": None
            }
        
        if not company_name or not company_name.strip():
            return {
                "success": False,
                "error": "Company name is empty",
                "result": None
            }
        
        if not position_title or not position_title.strip():
            return {
                "success": False,
                "error": "Position title is empty", 
                "result": None
            }
        
        # æ£€æµ‹è¯­è¨€
        combined_text = f"{jd_content} {company_name} {position_title}"
        detected_language = self._detect_language(combined_text)
        
        # æ„å»ºå®Œæ•´çš„prompt
        full_prompt = f"""{self.prompt_template}

## Input Information

**JD Content (èŒä½æè¿°):**
{jd_content.strip()}

**Company Name (å…¬å¸åç§°):**
{company_name.strip()}

**Position Title (å²—ä½æ ‡é¢˜):**
{position_title.strip()}

Please analyze this job position following the framework provided above."""
        
        messages = [
            {
                "role": "user",
                "content": full_prompt
            }
        ]
        
        # åˆå¹¶é»˜è®¤å‚æ•°å’Œä¼ å…¥å‚æ•°
        llm_params = {
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "top_p": self.top_p,
            "frequency_penalty": self.frequency_penalty,
            "presence_penalty": self.presence_penalty,
            **kwargs  # ä¼ å…¥çš„å‚æ•°ä¼šè¦†ç›–é»˜è®¤å‚æ•°
        }
        
        try:
            # è°ƒç”¨LLM
            response = self.llm_client.call_llm(
                provider=self.provider,
                model=self.model,
                messages=messages,
                **llm_params
            )
            
            if not response.get("success"):
                return {
                    "success": False,
                    "error": f"LLM call failed: {response.get('error', 'Unknown error')}",
                    "result": None,
                    "raw_response": response
                }
            
            # æå–å“åº”å†…å®¹
            content = self.llm_client.get_response_content(response)
            if not content:
                return {
                    "success": False,
                    "error": "No content in LLM response",
                    "result": None,
                    "raw_response": response
                }
            
            return {
                "success": True,
                "result": {
                    "analysis": content,
                    "input_info": {
                        "jd_content": jd_content,
                        "company_name": company_name,
                        "position_title": position_title
                    },
                    "detected_language": detected_language
                },
                "raw_content": content,
                "usage": response.get("data", {}).get("usage", {}),
                "model_used": response.get("data", {}).get("model", self.model),
                "provider": self.provider
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"Analysis failed: {str(e)}",
                "result": None
            }
    
    def save_analysis_result(
        self, 
        result: Dict[str, Any], 
        output_file: Optional[str] = None
    ) -> str:
        """
        ä¿å­˜åˆ†æç»“æœåˆ°æ–‡ä»¶
        
        Args:
            result: åˆ†æç»“æœ
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if not output_file:
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"job_analysis_result_{timestamp}.txt"
        
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                if result.get("success"):
                    # å†™å…¥åˆ†æç»“æœ
                    f.write("=" * 80 + "\n")
                    f.write("JOB ANALYSIS RESULT\n")
                    f.write("=" * 80 + "\n\n")
                    
                    # è¾“å…¥ä¿¡æ¯
                    input_info = result["result"]["input_info"]
                    f.write("INPUT INFORMATION:\n")
                    f.write("-" * 40 + "\n")
                    f.write(f"Company: {input_info['company_name']}\n")
                    f.write(f"Position: {input_info['position_title']}\n")
                    f.write(f"Language: {result['result']['detected_language']}\n")
                    f.write(f"Model: {result.get('model_used', 'N/A')}\n")
                    f.write(f"Provider: {result.get('provider', 'N/A')}\n\n")
                    
                    # JDå†…å®¹
                    f.write("JOB DESCRIPTION:\n")
                    f.write("-" * 40 + "\n")
                    f.write(f"{input_info['jd_content']}\n\n")
                    
                    # åˆ†æç»“æœ
                    f.write("ANALYSIS RESULT:\n")
                    f.write("-" * 40 + "\n")
                    f.write(f"{result['result']['analysis']}\n\n")
                    
                    # ä½¿ç”¨ç»Ÿè®¡
                    if result.get("usage"):
                        usage = result["usage"]
                        f.write("USAGE STATISTICS:\n")
                        f.write("-" * 40 + "\n")
                        f.write(f"Prompt tokens: {usage.get('prompt_tokens', 'N/A')}\n")
                        f.write(f"Completion tokens: {usage.get('completion_tokens', 'N/A')}\n")
                        f.write(f"Total tokens: {usage.get('total_tokens', 'N/A')}\n")
                    
                else:
                    f.write("ANALYSIS FAILED\n")
                    f.write("=" * 40 + "\n")
                    f.write(f"Error: {result.get('error', 'Unknown error')}\n")
            
            return output_file
            
        except Exception as e:
            print(f"Failed to save result to file: {e}")
            return None
    
    def get_supported_providers(self) -> List[str]:
        """
        è·å–æ”¯æŒçš„LLMæä¾›å•†åˆ—è¡¨
        
        Returns:
            æ”¯æŒçš„æä¾›å•†åˆ—è¡¨
        """
        return ["openai", "gemini", "ali", "groq", "perplexity"]
    
    def get_recommended_models(self, provider: str) -> List[str]:
        """
        è·å–æ¨èçš„æ¨¡å‹åˆ—è¡¨
        
        Args:
            provider: æä¾›å•†åç§°
            
        Returns:
            æ¨èçš„æ¨¡å‹åˆ—è¡¨
        """
        models = {
            "openai": ["gpt-4-1106-preview", "gpt-4", "gpt-3.5-turbo"],
            "gemini": ["gemini-2.5-flash-lite", "gemini-1.5-pro", "gemini-1.5-flash"],
            "ali": ["deepseek-v3", "qwen-max", "qwen-turbo", "qwen-plus"],
            "groq": ["llama-3.1-70b-versatile", "llama-3.1-8b-instant", "mixtral-8x7b-32768"],
            "perplexity": ["llama-3.1-sonar-large-128k-online", "llama-3.1-sonar-small-128k-online"]
        }
        
        return models.get(provider.lower(), [])


if __name__ == "__main__":
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) < 4:
        print("Usage: python job_analyzer.py \"JD_CONTENT\" \"COMPANY_NAME\" \"POSITION_TITLE\"")
        print("\nExample:")
        print('python job_analyzer.py "We are looking for a senior product manager..." "Tencent" "Senior Product Manager"')
        sys.exit(1)
    
    # è·å–è¾“å…¥å‚æ•°
    jd_content = sys.argv[1]
    company_name = sys.argv[2] 
    position_title = sys.argv[3]
    
    # åˆ›å»ºåˆ†æå™¨å®ä¾‹ - ä½¿ç”¨Gemini 2.5
    analyzer = JobAnalyzer(
        model="gemini-2.5-flash-lite",
        provider="gemini",
        temperature=0.3,
        max_tokens=4000
    )
    
    print(f"ğŸ¢ Company: {company_name}")
    print(f"ğŸ“‹ Position: {position_title}")
    print(f"ğŸ“„ JD Content: {jd_content[:100]}{'...' if len(jd_content) > 100 else ''}")
    print("-" * 80)
    print("ğŸ”„ Analyzing job position...")
    
    # åˆ†æå²—ä½
    result = analyzer.analyze_job(jd_content, company_name, position_title)
    
    # è¾“å‡ºç»“æœ
    if result["success"]:
        print("âœ… Analysis successful!")
        print("\n" + "=" * 80)
        print("ANALYSIS RESULT:")
        print("=" * 80)
        print(result["result"]["analysis"])
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        output_file = analyzer.save_analysis_result(result)
        if output_file:
            print(f"\nğŸ’¾ Result saved to: {output_file}")
        
        # æ˜¾ç¤ºä½¿ç”¨ç»Ÿè®¡
        if "usage" in result:
            usage = result["usage"]
            print(f"\nğŸ“Š Usage Statistics:")
            print(f"  Prompt tokens: {usage.get('prompt_tokens', 'N/A')}")
            print(f"  Completion tokens: {usage.get('completion_tokens', 'N/A')}")
            print(f"  Total tokens: {usage.get('total_tokens', 'N/A')}")
        
        print(f"\nğŸ¤– Model: {result.get('model_used', 'N/A')}")
        print(f"ğŸ”§ Provider: {result.get('provider', 'N/A')}")
        print(f"ğŸŒ Language: {result['result']['detected_language']}")
        
    else:
        print("âŒ Analysis failed!")
        print(f"Error: {result['error']}")
        if "raw_response" in result:
            print(f"Raw response: {result['raw_response']}")