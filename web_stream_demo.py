#!/usr/bin/env python3
"""
Web æµå¼å“åº”æ¼”ç¤º
ä½¿ç”¨ Flask å±•ç¤ºå¦‚ä½•å°†æµå¼å°è£…é›†æˆåˆ° Web åº”ç”¨ä¸­
"""

import sys
from pathlib import Path
import json
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

try:
    from flask import Flask, request, Response, render_template_string, jsonify
    from flask_cors import CORS
except ImportError:
    print("âŒ éœ€è¦å®‰è£… Flask å’Œ flask-cors:")
    print("   pip install flask flask-cors")
    sys.exit(1)

from api.llm import LLMClient
from api.stream import create_stream_response


app = Flask(__name__)
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚


# ç®€å•çš„å‰ç«¯é¡µé¢æ¨¡æ¿
HTML_TEMPLATE = """
<!DOCTYPE html>
<html>
<head>
    <title>LLM æµå¼å“åº”æ¼”ç¤º</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; }
        .container { max-width: 800px; margin: 0 auto; }
        #messages { border: 1px solid #ddd; height: 400px; overflow-y: auto; padding: 10px; margin: 10px 0; }
        .message { margin: 5px 0; padding: 5px; background: #f5f5f5; border-radius: 3px; }
        .user { background: #e3f2fd; }
        .assistant { background: #f3e5f5; }
        .error { background: #ffebee; color: #c62828; }
        input, select, button { margin: 5px; padding: 8px; }
        #userInput { width: 60%; }
        #sendBtn { background: #4caf50; color: white; border: none; cursor: pointer; }
        #sendBtn:disabled { background: #cccccc; cursor: not-allowed; }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸŒŠ LLM æµå¼å“åº”æ¼”ç¤º</h1>
        
        <div>
            <select id="provider">
                <option value="openai">OpenAI</option>
                <option value="gemini">Gemini</option>
                <option value="perplexity">Perplexity</option>
                <option value="groq">Groq</option>
            </select>
            
            <select id="model">
                <option value="gpt-4-1106-preview">GPT-4 Turbo</option>
                <option value="gemini-2.5-flash-lite">Gemini 2.5 Flash Lite</option>
                <option value="sonar-pro">Perplexity Sonar Pro</option>
                <option value="llama-3.1-70b-versatile">Llama 3.1 70B</option>
            </select>
        </div>
        
        <div>
            <input type="text" id="userInput" placeholder="è¾“å…¥æ‚¨çš„é—®é¢˜..." />
            <button id="sendBtn" onclick="sendMessage()">å‘é€</button>
        </div>
        
        <div id="messages"></div>
    </div>

    <script>
        const messagesDiv = document.getElementById('messages');
        const userInput = document.getElementById('userInput');
        const sendBtn = document.getElementById('sendBtn');
        
        // æä¾›å•†å’Œæ¨¡å‹çš„æ˜ å°„
        const providerModels = {
            'openai': ['gpt-4-1106-preview', 'gpt-3.5-turbo'],
            'gemini': ['gemini-2.5-flash-lite', 'gemini-1.5-pro'],
            'perplexity': ['sonar-pro', 'llama-3.1-sonar-small-128k-online'],
            'groq': ['llama-3.1-70b-versatile', 'llama-3.1-8b-instant']
        };
        
        // æ›´æ–°æ¨¡å‹é€‰é¡¹
        document.getElementById('provider').addEventListener('change', function() {
            const provider = this.value;
            const modelSelect = document.getElementById('model');
            modelSelect.innerHTML = '';
            
            providerModels[provider].forEach(model => {
                const option = document.createElement('option');
                option.value = model;
                option.textContent = model;
                modelSelect.appendChild(option);
            });
        });
        
        function addMessage(content, isUser, isError = false) {
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${isUser ? 'user' : 'assistant'} ${isError ? 'error' : ''}`;
            messageDiv.textContent = content;
            messagesDiv.appendChild(messageDiv);
            messagesDiv.scrollTop = messagesDiv.scrollHeight;
        }
        
        function sendMessage() {
            const message = userInput.value.trim();
            if (!message) return;
            
            const provider = document.getElementById('provider').value;
            const model = document.getElementById('model').value;
            
            addMessage(message, true);
            userInput.value = '';
            sendBtn.disabled = true;
            
            // åˆ›å»ºä¸€ä¸ªå ä½æ¶ˆæ¯ç”¨äºæ˜¾ç¤ºæµå¼å†…å®¹
            const assistantDiv = document.createElement('div');
            assistantDiv.className = 'message assistant';
            assistantDiv.textContent = 'æ€è€ƒä¸­...';
            messagesDiv.appendChild(assistantDiv);
            messagesDiv.scrollTop = messagesDiv.scrollHeight;
            
            // å»ºç«‹ SSE è¿æ¥
            const eventSource = new EventSource(`/stream?message=${encodeURIComponent(message)}&provider=${provider}&model=${model}`);
            
            let content = '';
            
            eventSource.onmessage = function(event) {
                if (event.data === '[DONE]') {
                    eventSource.close();
                    sendBtn.disabled = false;
                    return;
                }
                
                try {
                    const data = JSON.parse(event.data);
                    console.log('æ”¶åˆ°æ•°æ®:', data); // è°ƒè¯•æ—¥å¿—
                    
                    if (data.error) {
                        assistantDiv.className += ' error';
                        assistantDiv.textContent = `é”™è¯¯: ${data.error}`;
                        eventSource.close();
                        sendBtn.disabled = false;
                    } else if (data.content) {
                        content += data.content;
                        assistantDiv.textContent = content;
                    } else if (data.type === 'finish') {
                        // å¤„ç†ç»“æŸä¿¡æ¯
                        console.log('æµå¼å“åº”å®Œæˆ:', data.metadata);
                        // ä¸å…³é—­è¿æ¥ï¼Œç­‰å¾… [DONE]
                    }
                    
                    messagesDiv.scrollTop = messagesDiv.scrollHeight;
                } catch (e) {
                    console.error('è§£æå“åº”å¤±è´¥:', e, event.data);
                }
            };
            
            eventSource.onerror = function(event) {
                console.error('SSE è¿æ¥é”™è¯¯:', event);
                eventSource.close();
                if (content.length === 0) {
                    assistantDiv.className += ' error';
                    assistantDiv.textContent = 'è¿æ¥é”™è¯¯ï¼Œè¯·é‡è¯•';
                }
                sendBtn.disabled = false;
            };
            
            // æ·»åŠ è¶…æ—¶å¤„ç†
            const timeoutId = setTimeout(() => {
                if (eventSource.readyState !== EventSource.CLOSED) {
                    console.log('è¯·æ±‚è¶…æ—¶ï¼Œå…³é—­è¿æ¥');
                    eventSource.close();
                    if (content.length === 0) {
                        assistantDiv.className += ' error';
                        assistantDiv.textContent = 'è¯·æ±‚è¶…æ—¶ï¼Œè¯·é‡è¯•';
                    }
                    sendBtn.disabled = false;
                }
            }, 30000); // 30ç§’è¶…æ—¶
            
            // æ¸…ç†å®šæ—¶å™¨
            const originalClose = eventSource.close.bind(eventSource);
            eventSource.close = function() {
                clearTimeout(timeoutId);
                originalClose();
            };
        }
        
        // å›è½¦é”®å‘é€æ¶ˆæ¯
        userInput.addEventListener('keypress', function(e) {
            if (e.key === 'Enter' && !sendBtn.disabled) {
                sendMessage();
            }
        });
        
        // åˆå§‹åŒ–æ¨¡å‹é€‰é¡¹
        document.getElementById('provider').dispatchEvent(new Event('change'));
    </script>
</body>
</html>
"""


@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template_string(HTML_TEMPLATE)


@app.route('/stream')
def stream_chat():
    """æµå¼èŠå¤©ç«¯ç‚¹"""
    message = request.args.get('message', '')
    provider = request.args.get('provider', 'openai')
    model = request.args.get('model', 'gpt-4-1106-preview')
    
    if not message:
        return jsonify({"error": "Message is required"}), 400
    
    def generate_stream():
        """ç”Ÿæˆå™¨å‡½æ•°ï¼Œç”¨äº SSE å“åº”"""
        try:
            llm = LLMClient()
            
            # è·å–åŸå§‹æµ
            raw_stream = llm.stream_llm(
                provider=provider,
                model=model,
                messages=[{"role": "user", "content": message}],
                temperature=0.7,
                max_tokens=500
            )
            
            # åˆ›å»ºç»Ÿä¸€æµå¼å“åº”
            stream_response = create_stream_response(raw_stream, provider)
            
            # è½¬æ¢ä¸º SSE æ ¼å¼å¹¶å‘é€
            sent_content = False
            for sse_chunk in stream_response.to_sse():
                if 'data:' in sse_chunk and sse_chunk.strip() != 'data: [DONE]':
                    sent_content = True
                yield sse_chunk
            
            # å¦‚æœæ²¡æœ‰å‘é€ä»»ä½•å†…å®¹ï¼Œå‘é€ä¸€ä¸ªç©ºå“åº”
            if not sent_content:
                empty_response = json.dumps({
                    "content": "æŠ±æ­‰ï¼Œæ²¡æœ‰æ”¶åˆ°å“åº”å†…å®¹ã€‚",
                    "type": "content"
                })
                yield f"data: {empty_response}\n\n"
                yield "data: [DONE]\n\n"
                
        except Exception as e:
            # å‘é€é”™è¯¯ä¿¡æ¯
            error_data = json.dumps({
                "error": f"æœåŠ¡å™¨é”™è¯¯: {str(e)}",
                "type": "error"
            })
            yield f"data: {error_data}\n\n"
            yield "data: [DONE]\n\n"
    
    return Response(
        generate_stream(),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
            'Access-Control-Allow-Origin': '*',
            'Access-Control-Allow-Headers': 'Cache-Control'
        }
    )


@app.route('/api/chat', methods=['POST'])
def api_chat():
    """API ç«¯ç‚¹ï¼šéæµå¼èŠå¤©"""
    data = request.get_json()
    if not data or 'message' not in data:
        return jsonify({"error": "Message is required"}), 400
    
    message = data['message']
    provider = data.get('provider', 'openai')
    model = data.get('model', 'gpt-4-1106-preview')
    
    try:
        llm = LLMClient()
        
        # è·å–åŸå§‹æµ
        raw_stream = llm.stream_llm(
            provider=provider,
            model=model,
            messages=[{"role": "user", "content": message}],
            temperature=0.7,
            max_tokens=500
        )
        
        # åˆ›å»ºç»Ÿä¸€æµå¼å“åº”å¹¶æ”¶é›†å®Œæ•´å“åº”
        stream_response = create_stream_response(raw_stream, provider)
        full_response = stream_response.collect_full_response()
        
        return jsonify(full_response)
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route('/api/providers')
def get_providers():
    """è·å–æ”¯æŒçš„æä¾›å•†å’Œæ¨¡å‹åˆ—è¡¨"""
    return jsonify({
        "providers": {
            "openai": ["gpt-4-1106-preview", "gpt-3.5-turbo"],
            "gemini": ["gemini-2.5-flash-lite", "gemini-1.5-pro"],
            "perplexity": ["sonar-pro", "llama-3.1-sonar-small-128k-online"],
            "groq": ["llama-3.1-70b-versatile", "llama-3.1-8b-instant"]
        }
    })


if __name__ == '__main__':
    print("ğŸŒŠ å¯åŠ¨ Web æµå¼å“åº”æ¼”ç¤º")
    print("=" * 50)
    print("ğŸ“± è®¿é—®åœ°å€: http://localhost:5000")
    print("ğŸ”— API ç«¯ç‚¹:")
    print("   GET  /              - ä¸»é¡µï¼ˆæ¼”ç¤ºç•Œé¢ï¼‰")
    print("   GET  /stream        - SSE æµå¼èŠå¤©")
    print("   POST /api/chat      - éæµå¼ API")
    print("   GET  /api/providers - è·å–æ”¯æŒçš„æä¾›å•†")
    print("=" * 50)
    print("ğŸ’¡ ä½¿ç”¨è¯´æ˜:")
    print("   1. åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ http://localhost:5000")
    print("   2. é€‰æ‹© LLM æä¾›å•†å’Œæ¨¡å‹")
    print("   3. è¾“å…¥é—®é¢˜å¹¶å‘é€")
    print("   4. è§‚å¯Ÿæµå¼å“åº”æ•ˆæœ")
    print("=" * 50)
    
    app.run(debug=True, host='0.0.0.0', port=5000)